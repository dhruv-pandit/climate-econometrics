{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from tqdm import tqdm  # Optional: For progress tracking\n",
    "from scipy.interpolate import griddata\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 Data Documentation\n",
    "- data documented here: https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation#heading-Meanratesfluxesandaccumulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading NetCDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_nc = xr.open_dataset(r'../datasets/era5/reanalysis_selected.nc')\n",
    "mun_gdf = gpd.read_file(r'../datasets/municipality_data/municipalities-shapefile-2/concelhos.shp')\n",
    "reanalysis_df = reanalysis_nc.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the folder containing the NetCDF files\n",
    "folder_path = '../datasets/era5/net_cdf_hourly/'\n",
    "\n",
    "# List to store individual DataFrames\n",
    "hourly_dfs = []\n",
    "quarterly_dfs = []\n",
    "yearly_dfs = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.nc'):  # Check if the file is a NetCDF file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Open the NetCDF file as an xarray dataset\n",
    "        hourly_ds = xr.open_dataset(file_path)\n",
    "        # Drop Irrelevant Variables \n",
    "        hourly_ds = hourly_ds.drop_vars('sst')\n",
    "        hourly_ds['tp_1000'] = hourly_ds['tp'] * 1000\n",
    "        hourly_ds['sp'] = hourly_ds['sp'] * 100\n",
    "\n",
    "        # Resample Data On Day, Aggregating \n",
    "        daily_means = hourly_ds.resample(time='D').mean('time')\n",
    "        # Resample Data On Month, Aggregating\n",
    "        monthly_stddevs = daily_means.resample(time='M').std('time')\n",
    "        \n",
    "        quarterly_stddevs = monthly_stddevs.resample(time='Q').mean('time')\n",
    "        avg_year_stddev = monthly_stddevs.resample(time = 'Y').mean('time')\n",
    "        # Convert the xarray dataset to a DataFrame\n",
    "        hourly_df = monthly_stddevs.to_dataframe()\n",
    "\n",
    "        quarterly_df = quarterly_stddevs.to_dataframe()\n",
    "        yearly_df = avg_year_stddev.to_dataframe()\n",
    "        # Append the DataFrame to the list\n",
    "        hourly_dfs.append(hourly_df)\n",
    "        quarterly_dfs.append(quarterly_df)\n",
    "        yearly_dfs.append(yearly_df)\n",
    "# Concatenate all individual DataFrames into one\n",
    "erA5_std_df = pd.concat(hourly_dfs, axis=0)\n",
    "\n",
    "erA5_std_df_q = pd.concat(quarterly_dfs, axis=0)\n",
    "erA5_std_df_y = pd.concat(yearly_dfs, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarterly Data Index Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time index to 'YYYYQQ' format\n",
    "quarterly_index = erA5_std_df_q.index.set_levels(erA5_std_df_q.index.levels[2].to_series().dt.to_period('Q').dt.strftime('%YQ%q'), level=2)\n",
    "\n",
    "# Assign the new index to the dataframe\n",
    "erA5_std_df_q.index = quarterly_index\n",
    "\n",
    "erA5_std_df_q = erA5_std_df_q.sort_index(level = ['latitude', 'longitude', 'time'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly Data Index Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time index to 'YYYYQQ' format\n",
    "yearly_index = erA5_std_df_y.index.set_levels(erA5_std_df_y.index.levels[2].to_series().dt.to_period('Y').dt.strftime('%Y'), level=2)\n",
    "\n",
    "# Assign the new index to the dataframe\n",
    "erA5_std_df_y.index = yearly_index\n",
    "\n",
    "erA5_std_df_y = erA5_std_df_y.sort_index(level = ['latitude', 'longitude', 'time'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Data Index Reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6c/vby383sn3xlg0j_c253f0sf40000gn/T/ipykernel_62077/3176136934.py:3: FutureWarning: inplace is deprecated and will be removed in a future version.\n",
      "  erA5_std_df.index.set_levels(levels = erA5_std_df.index.levels[2].strftime('%Y-%m-01'), level=2, inplace=True)\n",
      "/var/folders/6c/vby383sn3xlg0j_c253f0sf40000gn/T/ipykernel_62077/3176136934.py:4: FutureWarning: inplace is deprecated and will be removed in a future version.\n",
      "  erA5_std_df.index.set_levels(levels = pd.DatetimeIndex(erA5_std_df.index.levels[2]),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>msl</th>\n",
       "      <th>stl2</th>\n",
       "      <th>sp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_1000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-9.50</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">36.919998</th>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>0.750060</td>\n",
       "      <td>623.241089</td>\n",
       "      <td>0.234960</td>\n",
       "      <td>62327.214844</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.075129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-01</th>\n",
       "      <td>0.710210</td>\n",
       "      <td>386.238037</td>\n",
       "      <td>0.201591</td>\n",
       "      <td>38623.707031</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-03-01</th>\n",
       "      <td>0.810310</td>\n",
       "      <td>514.520447</td>\n",
       "      <td>0.243901</td>\n",
       "      <td>51452.785156</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.482791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-04-01</th>\n",
       "      <td>0.780361</td>\n",
       "      <td>675.136414</td>\n",
       "      <td>0.191418</td>\n",
       "      <td>67516.000000</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.145437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-05-01</th>\n",
       "      <td>0.737124</td>\n",
       "      <td>308.730927</td>\n",
       "      <td>0.687092</td>\n",
       "      <td>30875.253906</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.015668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-6.25</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">41.919998</th>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>2.802478</td>\n",
       "      <td>251.069351</td>\n",
       "      <td>2.059406</td>\n",
       "      <td>22761.765625</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.024456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>2.830676</td>\n",
       "      <td>316.210968</td>\n",
       "      <td>2.193844</td>\n",
       "      <td>28969.507812</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.131304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>2.053990</td>\n",
       "      <td>413.500397</td>\n",
       "      <td>1.834660</td>\n",
       "      <td>41110.738281</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.218981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>2.218427</td>\n",
       "      <td>548.399475</td>\n",
       "      <td>1.671918</td>\n",
       "      <td>48648.960938</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.120530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>2.924474</td>\n",
       "      <td>847.471741</td>\n",
       "      <td>1.998029</td>\n",
       "      <td>78596.664062</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.229243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116424 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     t2m         msl      stl2            sp  \\\n",
       "longitude latitude  time                                                       \n",
       "-9.50     36.919998 1990-01-01  0.750060  623.241089  0.234960  62327.214844   \n",
       "                    1990-02-01  0.710210  386.238037  0.201591  38623.707031   \n",
       "                    1990-03-01  0.810310  514.520447  0.243901  51452.785156   \n",
       "                    1990-04-01  0.780361  675.136414  0.191418  67516.000000   \n",
       "                    1990-05-01  0.737124  308.730927  0.687092  30875.253906   \n",
       "...                                  ...         ...       ...           ...   \n",
       "-6.25     41.919998 2022-08-01  2.802478  251.069351  2.059406  22761.765625   \n",
       "                    2022-09-01  2.830676  316.210968  2.193844  28969.507812   \n",
       "                    2022-10-01  2.053990  413.500397  1.834660  41110.738281   \n",
       "                    2022-11-01  2.218427  548.399475  1.671918  48648.960938   \n",
       "                    2022-12-01  2.924474  847.471741  1.998029  78596.664062   \n",
       "\n",
       "                                      tp   tp_1000  \n",
       "longitude latitude  time                            \n",
       "-9.50     36.919998 1990-01-01  0.000075  0.075129  \n",
       "                    1990-02-01  0.000004  0.003643  \n",
       "                    1990-03-01  0.000483  0.482791  \n",
       "                    1990-04-01  0.000145  0.145437  \n",
       "                    1990-05-01  0.000016  0.015668  \n",
       "...                                  ...       ...  \n",
       "-6.25     41.919998 2022-08-01  0.000024  0.024456  \n",
       "                    2022-09-01  0.000131  0.131304  \n",
       "                    2022-10-01  0.000219  0.218981  \n",
       "                    2022-11-01  0.000121  0.120530  \n",
       "                    2022-12-01  0.000229  0.229243  \n",
       "\n",
       "[116424 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erA5_std_df = erA5_std_df.sort_index(level = ['latitude', 'longitude', 'time'], ascending=True)\n",
    "# Convert the 'time' level to the first day of each month\n",
    "erA5_std_df.index.set_levels(levels = erA5_std_df.index.levels[2].strftime('%Y-%m-01'), level=2, inplace=True)\n",
    "erA5_std_df.index.set_levels(levels = pd.DatetimeIndex(erA5_std_df.index.levels[2]),\n",
    "    level=2,\n",
    "    inplace=True\n",
    ")\n",
    "erA5_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Months: DatetimeIndex([], dtype='datetime64[ns]', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "# Create a complete date range from '1990-01-01' to '2022-12-01'\n",
    "complete_date_range = pd.date_range(start='1990-01-01', end='2022-12-01', freq='MS')\n",
    "\n",
    "# Identify the missing months\n",
    "missing_months = complete_date_range.difference(erA5_std_df.index.levels[2].unique())\n",
    "\n",
    "# Print or use the missing months as needed\n",
    "print(\"Missing Months:\", missing_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining historical mean values, and deviations from historical means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_df['tp_1000'] = reanalysis_df['tp'] * 1000\n",
    "mean_monthly_values = reanalysis_df.loc[pd.IndexSlice[:, :, :, '1940-01-01':'1980-12-01']].groupby(['longitude','latitude']).mean()\n",
    "historical_deviations = reanalysis_df - mean_monthly_values\n",
    "historical_deviations = historical_deviations.loc[pd.IndexSlice[:, :, :, '1980-06-01':'2023-06-01']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>msl</th>\n",
       "      <th>sst</th>\n",
       "      <th>stl2</th>\n",
       "      <th>sp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_1000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>expver</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-9.50</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">41.919998</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1940-01-01</th>\n",
       "      <td>284.716980</td>\n",
       "      <td>101395.757812</td>\n",
       "      <td>286.415314</td>\n",
       "      <td>286.425781</td>\n",
       "      <td>101369.875000</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>4.636065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-02-01</th>\n",
       "      <td>285.627289</td>\n",
       "      <td>101372.671875</td>\n",
       "      <td>286.103516</td>\n",
       "      <td>286.106018</td>\n",
       "      <td>101346.085938</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>6.822389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-03-01</th>\n",
       "      <td>286.070496</td>\n",
       "      <td>101516.382812</td>\n",
       "      <td>286.168213</td>\n",
       "      <td>286.161987</td>\n",
       "      <td>101491.078125</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>2.883197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-04-01</th>\n",
       "      <td>286.509277</td>\n",
       "      <td>101767.781250</td>\n",
       "      <td>287.100616</td>\n",
       "      <td>287.081421</td>\n",
       "      <td>101741.781250</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>2.486443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940-05-01</th>\n",
       "      <td>287.809998</td>\n",
       "      <td>101585.351562</td>\n",
       "      <td>288.514832</td>\n",
       "      <td>288.489960</td>\n",
       "      <td>101558.859375</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>1.213488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-6.25</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">36.919998</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01</th>\n",
       "      <td>295.216125</td>\n",
       "      <td>101550.421875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297.281799</td>\n",
       "      <td>101351.476562</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>2.553807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591528 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              t2m            msl         sst  \\\n",
       "longitude latitude  expver time                                                \n",
       "-9.50     41.919998 1      1940-01-01  284.716980  101395.757812  286.415314   \n",
       "                           1940-02-01  285.627289  101372.671875  286.103516   \n",
       "                           1940-03-01  286.070496  101516.382812  286.168213   \n",
       "                           1940-04-01  286.509277  101767.781250  287.100616   \n",
       "                           1940-05-01  287.809998  101585.351562  288.514832   \n",
       "...                                           ...            ...         ...   \n",
       "-6.25     36.919998 5      2023-06-01         NaN            NaN         NaN   \n",
       "                           2023-07-01         NaN            NaN         NaN   \n",
       "                           2023-08-01         NaN            NaN         NaN   \n",
       "                           2023-09-01         NaN            NaN         NaN   \n",
       "                           2023-10-01  295.216125  101550.421875         NaN   \n",
       "\n",
       "                                             stl2             sp        tp  \\\n",
       "longitude latitude  expver time                                              \n",
       "-9.50     41.919998 1      1940-01-01  286.425781  101369.875000  0.004636   \n",
       "                           1940-02-01  286.106018  101346.085938  0.006822   \n",
       "                           1940-03-01  286.161987  101491.078125  0.002883   \n",
       "                           1940-04-01  287.081421  101741.781250  0.002486   \n",
       "                           1940-05-01  288.489960  101558.859375  0.001213   \n",
       "...                                           ...            ...       ...   \n",
       "-6.25     36.919998 5      2023-06-01         NaN            NaN       NaN   \n",
       "                           2023-07-01         NaN            NaN       NaN   \n",
       "                           2023-08-01         NaN            NaN       NaN   \n",
       "                           2023-09-01         NaN            NaN       NaN   \n",
       "                           2023-10-01  297.281799  101351.476562  0.002554   \n",
       "\n",
       "                                        tp_1000  \n",
       "longitude latitude  expver time                  \n",
       "-9.50     41.919998 1      1940-01-01  4.636065  \n",
       "                           1940-02-01  6.822389  \n",
       "                           1940-03-01  2.883197  \n",
       "                           1940-04-01  2.486443  \n",
       "                           1940-05-01  1.213488  \n",
       "...                                         ...  \n",
       "-6.25     36.919998 5      2023-06-01       NaN  \n",
       "                           2023-07-01       NaN  \n",
       "                           2023-08-01       NaN  \n",
       "                           2023-09-01       NaN  \n",
       "                           2023-10-01  2.553807  \n",
       "\n",
       "[591528 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reanalysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Same for Quarterly Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting and Resampling Monthly Means to Quarterly Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_df_q = reanalysis_nc.resample(time='Q').mean('time').to_dataframe()\n",
    "reanalysis_df_q['tp_1000'] = reanalysis_df_q['tp'] * 1000\n",
    "reanalysis_df_q = reanalysis_df_q.loc[pd.IndexSlice[:, :, 1, :], :].copy()\n",
    "reanalysis_df_q = reanalysis_df_q.droplevel('expver')\n",
    "# Convert the time index to 'YYYYQQ' format\n",
    "quarterly_index_m = reanalysis_df_q.index.set_levels(reanalysis_df_q.index.levels[2].to_series().dt.to_period('Q').dt.strftime('%YQ%q'), level=2)\n",
    "# Assign the new index to the dataframe\n",
    "reanalysis_df_q.index = quarterly_index_m\n",
    "\n",
    "reanalysis_df_q = reanalysis_df_q.sort_index(level = ['latitude', 'longitude', 'time'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_qaurt_values = reanalysis_df_q.sort_index().loc[pd.IndexSlice[:, :,'1940Q1': '1980Q4']].groupby(['longitude','latitude']).mean()\n",
    "historical_deviations_q = reanalysis_df_q - mean_qaurt_values\n",
    "historical_deviations_q = historical_deviations_q.loc[pd.IndexSlice[:, :, '1990Q1':'2022Q4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly Average Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reanalysis_df_y = reanalysis_nc.resample(time='Y').mean('time').to_dataframe()\n",
    "reanalysis_df_y['tp_1000'] = reanalysis_df_y['tp'] * 1000\n",
    "reanalysis_df_y = reanalysis_df_y.loc[pd.IndexSlice[:, :, 1, :], :].copy()\n",
    "reanalysis_df_y = reanalysis_df_y.droplevel('expver')\n",
    "# Convert the time index to 'YYYYQQ' format\n",
    "yearly_index_m = reanalysis_df_y.index.set_levels(reanalysis_df_y.index.levels[2].to_series().dt.to_period('Y').dt.strftime('%Y'), level=2)\n",
    "# Assign the new index to the dataframe\n",
    "reanalysis_df_y.index = yearly_index_m\n",
    "\n",
    "reanalysis_df_y = reanalysis_df_y.sort_index(level = ['latitude', 'longitude', 'time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_year_values = reanalysis_df_y.sort_index().loc[pd.IndexSlice[:, :,'1940': '1980']].groupby(['longitude','latitude']).mean()\n",
    "historical_deviations_y = reanalysis_df_y - mean_year_values\n",
    "historical_deviations_y = historical_deviations_y.loc[pd.IndexSlice[:, :, '1990':'2022']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning Seasonal Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>msl</th>\n",
       "      <th>sst</th>\n",
       "      <th>stl2</th>\n",
       "      <th>sp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_1000</th>\n",
       "      <th>season_autumn</th>\n",
       "      <th>season_spring</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>expver</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-9.50</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">36.919998</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1980-06-01</th>\n",
       "      <td>1.043762</td>\n",
       "      <td>56.390625</td>\n",
       "      <td>0.474884</td>\n",
       "      <td>0.450623</td>\n",
       "      <td>55.835938</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>-1.013062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-07-01</th>\n",
       "      <td>1.983398</td>\n",
       "      <td>-4.984375</td>\n",
       "      <td>1.189392</td>\n",
       "      <td>1.173615</td>\n",
       "      <td>-4.992188</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>-1.248605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-08-01</th>\n",
       "      <td>3.058868</td>\n",
       "      <td>-7.390625</td>\n",
       "      <td>2.082367</td>\n",
       "      <td>2.067413</td>\n",
       "      <td>-7.234375</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.952666</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-09-01</th>\n",
       "      <td>3.151703</td>\n",
       "      <td>55.914062</td>\n",
       "      <td>2.584442</td>\n",
       "      <td>2.590698</td>\n",
       "      <td>55.382812</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-1.040937</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-10-01</th>\n",
       "      <td>2.078186</td>\n",
       "      <td>82.593750</td>\n",
       "      <td>2.060059</td>\n",
       "      <td>2.079742</td>\n",
       "      <td>82.320312</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.389128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-6.25</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">41.919998</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303996 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            t2m        msl       sst  \\\n",
       "longitude latitude  expver time                                        \n",
       "-9.50     36.919998 1      1980-06-01  1.043762  56.390625  0.474884   \n",
       "                           1980-07-01  1.983398  -4.984375  1.189392   \n",
       "                           1980-08-01  3.058868  -7.390625  2.082367   \n",
       "                           1980-09-01  3.151703  55.914062  2.584442   \n",
       "                           1980-10-01  2.078186  82.593750  2.060059   \n",
       "...                                         ...        ...       ...   \n",
       "-6.25     41.919998 5      2023-02-01       NaN        NaN       NaN   \n",
       "                           2023-03-01       NaN        NaN       NaN   \n",
       "                           2023-04-01       NaN        NaN       NaN   \n",
       "                           2023-05-01       NaN        NaN       NaN   \n",
       "                           2023-06-01       NaN        NaN       NaN   \n",
       "\n",
       "                                           stl2         sp        tp  \\\n",
       "longitude latitude  expver time                                        \n",
       "-9.50     36.919998 1      1980-06-01  0.450623  55.835938 -0.001013   \n",
       "                           1980-07-01  1.173615  -4.992188 -0.001249   \n",
       "                           1980-08-01  2.067413  -7.234375 -0.000953   \n",
       "                           1980-09-01  2.590698  55.382812 -0.001041   \n",
       "                           1980-10-01  2.079742  82.320312 -0.000389   \n",
       "...                                         ...        ...       ...   \n",
       "-6.25     41.919998 5      2023-02-01       NaN        NaN       NaN   \n",
       "                           2023-03-01       NaN        NaN       NaN   \n",
       "                           2023-04-01       NaN        NaN       NaN   \n",
       "                           2023-05-01       NaN        NaN       NaN   \n",
       "                           2023-06-01       NaN        NaN       NaN   \n",
       "\n",
       "                                        tp_1000  season_autumn  season_spring  \\\n",
       "longitude latitude  expver time                                                 \n",
       "-9.50     36.919998 1      1980-06-01 -1.013062              0              0   \n",
       "                           1980-07-01 -1.248605              0              0   \n",
       "                           1980-08-01 -0.952666              0              0   \n",
       "                           1980-09-01 -1.040937              1              0   \n",
       "                           1980-10-01 -0.389128              1              0   \n",
       "...                                         ...            ...            ...   \n",
       "-6.25     41.919998 5      2023-02-01       NaN              0              0   \n",
       "                           2023-03-01       NaN              0              1   \n",
       "                           2023-04-01       NaN              0              1   \n",
       "                           2023-05-01       NaN              0              1   \n",
       "                           2023-06-01       NaN              0              0   \n",
       "\n",
       "                                       season_summer  season_winter  \n",
       "longitude latitude  expver time                                      \n",
       "-9.50     36.919998 1      1980-06-01              1              0  \n",
       "                           1980-07-01              1              0  \n",
       "                           1980-08-01              1              0  \n",
       "                           1980-09-01              0              0  \n",
       "                           1980-10-01              0              0  \n",
       "...                                              ...            ...  \n",
       "-6.25     41.919998 5      2023-02-01              0              1  \n",
       "                           2023-03-01              0              0  \n",
       "                           2023-04-01              0              0  \n",
       "                           2023-05-01              0              0  \n",
       "                           2023-06-01              1              0  \n",
       "\n",
       "[303996 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_deviations['season'] = historical_deviations.index.get_level_values('time').month.map({\n",
    "    12: 'winter', 1: 'winter', 2: 'winter',\n",
    "    3: 'spring', 4: 'spring', 5: 'spring',\n",
    "    6: 'summer', 7: 'summer', 8: 'summer',\n",
    "    9: 'autumn', 10: 'autumn', 11: 'autumn'\n",
    "})\n",
    "\n",
    "# Convert 'season' column to dummy variables\n",
    "historical_deviations = pd.get_dummies(historical_deviations, columns=['season'], prefix='season', )\n",
    "historical_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "erA5_std_df['season'] = erA5_std_df.index.get_level_values('time').month.map({\n",
    "    12: 'winter', 1: 'winter', 2: 'winter',\n",
    "    3: 'spring', 4: 'spring', 5: 'spring',\n",
    "    6: 'summer', 7: 'summer', 8: 'summer',\n",
    "    9: 'autumn', 10: 'autumn', 11: 'autumn'\n",
    "})\n",
    "\n",
    "# Convert 'season' column to dummy variables\n",
    "erA5_std_df = pd.get_dummies(erA5_std_df, columns=['season'], prefix='season', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolygonConversion:\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_geo_polygon(latitude: float, longitude: float, lat_grid_resolution: float, lon_grid_resolution: float) -> Polygon:\n",
    "        \"\"\"Create a Polygon based on latitude, longitude, and resolution.\n",
    "\n",
    "        Example ::\n",
    "            * - . - *\n",
    "            |       |\n",
    "            .   •   .\n",
    "            |       |\n",
    "            * - . - *\n",
    "        In order to create the polygon, we require the `*` point as indicated in the above example.\n",
    "        To determine the position of the `*` point, we find the `.` point.\n",
    "        The `get_lat_lon_range` function gives the `.` point and `bound_point` gives the `*` point.\n",
    "            \"\"\"        # Calculate the half-size of the bounding box\n",
    "        half_size_lon = lon_grid_resolution / 2\n",
    "        half_size_lat = lat_grid_resolution / 2\n",
    "        \n",
    "        # Calculate the bound points\n",
    "        lower_left = (longitude - half_size_lon, latitude - half_size_lat)\n",
    "        upper_left = (longitude - half_size_lon, latitude + half_size_lat)\n",
    "        upper_right = (longitude + half_size_lon, latitude + half_size_lat)\n",
    "        lower_right = (longitude + half_size_lon, latitude - half_size_lat)\n",
    "        \n",
    "        polygon = Polygon([lower_left, upper_left, upper_right, lower_right])\n",
    "        return polygon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Points from Lat,and Lon and Polygons centered on Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Polygons: 100%|██████████| 303996/303996 [00:06<00:00, 43751.29it/s]\n"
     ]
    }
   ],
   "source": [
    "polygon_converter = PolygonConversion()\n",
    "\n",
    "# Assume your dataset is named 'ds' (replace it with the actual name)\n",
    "# Accessing latitude and longitude from the dataset\n",
    "lats = historical_deviations.index.get_level_values('latitude').values\n",
    "lons = historical_deviations.index.get_level_values('longitude').values\n",
    "\n",
    "# Spatial resolution of your data\n",
    "lat_resolution = 0.25\n",
    "lon_resolution = 0.25\n",
    "\n",
    "# Create a DataFrame to store latitudes and longitudes\n",
    "df_points = pd.DataFrame({\n",
    "    'lat': lats,\n",
    "    'lon': lons\n",
    "})\n",
    "\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(lons, lats)]\n",
    "gdf_points = gpd.GeoDataFrame(geometry = geometry, crs=\"EPSG:4326\", index=historical_deviations.index)\n",
    "gdf_points.rename(columns = {'geometry' : 'points_geometry'}, inplace = True)\n",
    "# Create a GeoDataFrame with Polygon geometries\n",
    "polygons = []\n",
    "for _, row in tqdm(df_points.iterrows(), total=len(df_points), desc=\"Creating Polygons\"):\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    polygon = polygon_converter.fetch_geo_polygon(lat, lon, lat_resolution, lon_resolution)\n",
    "    polygons.append(polygon)\n",
    "\n",
    "# Create a GeoDataFrame with the constructed polygons\n",
    "gdf_polygons = gpd.GeoDataFrame(geometry=polygons, crs=\"EPSG:4326\")\n",
    "gdf_polygons = gdf_polygons.set_index(historical_deviations.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Polygons: 100%|██████████| 116424/116424 [00:02<00:00, 42616.79it/s]\n"
     ]
    }
   ],
   "source": [
    "polygon_converter = PolygonConversion()\n",
    "\n",
    "# Assume your dataset is named 'ds' (replace it with the actual name)\n",
    "# Accessing latitude and longitude from the dataset\n",
    "lats_std = erA5_std_df.index.get_level_values('latitude').values\n",
    "lons_std = erA5_std_df.index.get_level_values('longitude').values\n",
    "\n",
    "# Spatial resolution of your data\n",
    "lat_resolution = 0.25\n",
    "lon_resolution = 0.25\n",
    "\n",
    "# Create a DataFrame to store latitudes and longitudes\n",
    "df_points_std = pd.DataFrame({\n",
    "    'lat': lats_std,\n",
    "    'lon': lons_std\n",
    "})\n",
    "geometry_std = [Point(lon, lat) for lon, lat in zip(lons_std, lats_std)]\n",
    "gdf_points_std = gpd.GeoDataFrame(geometry = geometry_std, crs=\"EPSG:4326\", index=erA5_std_df.index)\n",
    "gdf_points_std.rename(columns = {'geometry' : 'points_geometry'}, inplace = True)\n",
    "\n",
    "# Create a GeoDataFrame with Polygon geometries\n",
    "polygons_std = []\n",
    "for _, row in tqdm(df_points_std.iterrows(), total=len(df_points_std), desc=\"Creating Polygons\"):\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    polygon = polygon_converter.fetch_geo_polygon(lat, lon, lat_resolution, lon_resolution)\n",
    "    polygons_std.append(polygon)\n",
    "\n",
    "# Create a GeoDataFrame with the constructed polygons\n",
    "gdf_polygons_std = gpd.GeoDataFrame(geometry=polygons_std, crs=\"EPSG:4326\")\n",
    "gdf_polygons_std = gdf_polygons_std.set_index(erA5_std_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Polygons with Renalysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract latitude and longitude from the MultiIndex DataFrame\n",
    "latitudes = historical_deviations.index.get_level_values('latitude').values\n",
    "longitudes = historical_deviations.index.get_level_values('longitude').values\n",
    "\n",
    "\n",
    "# Merge the GeoDataFrame into the MultiIndex DataFrame\n",
    "merged_df = pd.concat([historical_deviations, gdf_points, gdf_polygons], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract latitude and longitude from the MultiIndex DataFrame\n",
    "latitudes_std = erA5_std_df.index.get_level_values('latitude').values\n",
    "longitudes_std = erA5_std_df.index.get_level_values('longitude').values\n",
    "\n",
    "\n",
    "# Merge the GeoDataFrame into the MultiIndex DataFrame\n",
    "merged_std_df = pd.concat([erA5_std_df, gdf_points_std, gdf_polygons_std], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExpVer Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>msl</th>\n",
       "      <th>sst</th>\n",
       "      <th>stl2</th>\n",
       "      <th>sp</th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_1000</th>\n",
       "      <th>season_autumn</th>\n",
       "      <th>season_spring</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expver</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151998</td>\n",
       "      <td>151998</td>\n",
       "      <td>151998</td>\n",
       "      <td>151998</td>\n",
       "      <td>151998</td>\n",
       "      <td>151998</td>\n",
       "      <td>151998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t2m     msl     sst    stl2      sp      tp  tp_1000  \\\n",
       "expver                                                            \n",
       "1            0       0  118393       0       0       0        0   \n",
       "5       151998  151998  151998  151998  151998  151998   151998   \n",
       "\n",
       "        season_autumn  season_spring  season_summer  season_winter  \n",
       "expver                                                              \n",
       "1                   0              0              0              0  \n",
       "5                   0              0              0              0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_counts = historical_deviations.groupby('expver').apply(lambda x: x.isna().sum())\n",
    "nan_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest 3 months in this dataset are made available through ERA5T, which might be slightly different to ERA5. In the downloaded file, an extra dimenions ‘expver’ indicates which data is ERA5 (expver = 1) and which is ERA5T (expver = 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where expver is 1\n",
    "merged_df_1 = merged_df.loc[pd.IndexSlice[:, :, 1, :], :].copy()\n",
    "# Select rows where expver is 5\n",
    "merged_df_5 = merged_df.loc[pd.IndexSlice[:, :, 5, :], :].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping NaN Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_1 = merged_df_1.loc[pd.IndexSlice[:, :, :, '1990-01-01':'2022-12-01']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Xarray and Save NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_deviations_ds = merged_df_1[['t2m', 'msl', 'sst', 'stl2', 'sp', 'tp','tp_1000', 'season_autumn',\n",
    "       'season_spring', 'season_summer', 'season_winter']].to_xarray()\n",
    "std_ds = merged_std_df[['t2m', 'msl', 'stl2', 'sp', 'tp', 'tp_1000','season_autumn', 'season_spring',\n",
    "       'season_summer', 'season_winter']].to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_deviations_ds.to_netcdf(r'../datasets/era5/historical_deviations.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ds.to_netcdf(r'../datasets/era5/std_ds.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quarterly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_deviations_q.to_xarray().to_netcdf(r'../datasets/era5/historical_deviations_qaurt.nc')\n",
    "\n",
    "erA5_std_df_q.to_xarray().to_netcdf(r'../datasets/era5/std_ds_qaurt.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_deviations_y.to_xarray().to_netcdf(r'../datasets/era5/historical_deviations_y.nc')\n",
    "\n",
    "erA5_std_df_y.to_xarray().to_netcdf(r'../datasets/era5/std_ds_yearly.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
