{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point, box\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from tqdm import tqdm  # Optional: For progress tracking\n",
    "import os\n",
    "\n",
    "from shapely import wkt\n",
    "import contextily as cx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import unicodedata\n",
    "\n",
    "# Function to normalize the names\n",
    "def normalize_municipality_name(name):\n",
    "    if type(name) == float:\n",
    "        return name\n",
    "    else:\n",
    "        # Normalize the string (remove diacritical marks)\n",
    "        name_without_diacritics = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('ascii')\n",
    "        # Convert to lowercase\n",
    "        return name_without_diacritics.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mun_gdf = gpd.read_file(r'../../../countries/portugal/datasets/municipality_data/municipalities-shapefile-2/concelhos.shp')\n",
    "mun_metadata  = pd.read_excel(r'../../../countries/portugal/datasets/municipality_data/concelhos-metadata.xlsx', dtype={'dicofre' : 'string'})\n",
    "mun_metadata = mun_metadata[['dicofre','designacao']]\n",
    "\n",
    "mun_gdf = mun_gdf.merge(mun_metadata, left_on='CCA_2', right_on='dicofre').drop(columns='NAME_2')\n",
    "mun_gdf = mun_gdf.rename(columns={'designacao': 'NAME_2'})\n",
    "mun_gdf['concelho'] = mun_gdf['NAME_2'].map(normalize_municipality_name)\n",
    "mun_gdf = mun_gdf[~mun_gdf['NAME_1'].isin(['Azores', 'Madeira'])]\n",
    "west, south, east, north = mun_gdf.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above mun_gdf for portuguese municipalites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_to_municipality(\n",
    "    df, \n",
    "    municipalities_gdf, \n",
    "    grid_resolution=(0.25, 0.25), \n",
    "    time_range=(2013, 2023), \n",
    "    lat_col='latitude', \n",
    "    lon_col='longitude', \n",
    "    time_col='time', \n",
    "    municipality_id_col='concelho', \n",
    "    crs=\"EPSG:3763\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a cleaned DataFrame (from a parquet file) and aggregates its numerical variables \n",
    "    to the municipality level using area-weighted aggregation.\n",
    "    \n",
    "    The function performs the following steps:\n",
    "      1. Renames 'lat' or 'lon' columns to 'latitude' and 'longitude' if needed.\n",
    "      2. Filters the time column to years within time_range (if a time column exists).\n",
    "      3. Creates a GeoDataFrame from the lat/lon points.\n",
    "      4. Constructs square polygons centered on each point with the specified grid_resolution.\n",
    "      5. Reprojects the GeoDataFrame to the specified crs (defaults to EPSG:3763).\n",
    "      6. Uses an overlay with the provided municipalities to select only the grid cells that \n",
    "         fall within Portuguese boundaries.\n",
    "      7. Performs a spatial join so that each grid cell gets assigned its municipality.\n",
    "      8. Computes the area for each grid cell (vectorised).\n",
    "      9. For each numeric column (excluding lat, lon, time, geometry, and area),\n",
    "         computes an area-weighted value.\n",
    "     10. Groups the data by municipality (and time, if available) and sums the weighted values.\n",
    "    \n",
    "    Parameters:\n",
    "      df : pd.DataFrame\n",
    "          Input DataFrame containing the point-level data.\n",
    "      municipalities_gdf : gpd.GeoDataFrame\n",
    "          A GeoDataFrame with municipality polygons. This should either be in the target crs \n",
    "          or will be reprojected to it.\n",
    "      grid_resolution : tuple (lat_resolution, lon_resolution)\n",
    "          Resolution of the grid cells (polygons) to construct around each point.\n",
    "      time_range : tuple (start_year, end_year)\n",
    "          The inclusive range of years to keep (if a time column exists).\n",
    "      lat_col, lon_col : str\n",
    "          Column names for latitude and longitude. If the DataFrame has columns 'lat' or 'lon', \n",
    "          they will be renamed accordingly.\n",
    "      time_col : str\n",
    "          Column name for the time variable.\n",
    "      municipality_id_col : str\n",
    "          Column name in the municipalities GeoDataFrame that identifies the municipality.\n",
    "      crs : str\n",
    "          Target coordinate reference system. Default is \"EPSG:3763\".\n",
    "    \n",
    "    Returns:\n",
    "      pd.DataFrame\n",
    "          A DataFrame aggregated to the municipality level with area-weighted values.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import box\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # 1) Rename lat/lon if needed\n",
    "    if 'lat' in df.columns and lat_col != 'lat':\n",
    "        df = df.rename(columns={'lat': lat_col})\n",
    "    if 'lon' in df.columns and lon_col != 'lon':\n",
    "        df = df.rename(columns={'lon': lon_col})\n",
    "\n",
    "    # 2) If time_col exists, filter by time_range\n",
    "    if time_col in df.columns:\n",
    "        df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
    "        df = df[df[time_col].dt.year.between(time_range[0], time_range[1])]\n",
    "\n",
    "    # 3) Create GeoDataFrame of squares around each unique lat/lon\n",
    "    unique_coords = df[[lat_col, lon_col]].drop_duplicates().reset_index(drop=True)\n",
    "    unique_coords['polygon_id'] = range(len(unique_coords))\n",
    "\n",
    "    lat_res, lon_res = grid_resolution\n",
    "    half_lat = lat_res / 2.0\n",
    "    half_lon = lon_res / 2.0\n",
    "\n",
    "    gdf_points = gpd.GeoDataFrame(\n",
    "        unique_coords.copy(),\n",
    "        geometry=gpd.points_from_xy(unique_coords[lon_col], unique_coords[lat_col]),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    polygons = [\n",
    "        box(pt.x - half_lon, pt.y - half_lat, pt.x + half_lon, pt.y + half_lat)\n",
    "        for pt in tqdm(gdf_points.geometry, desc=\"Constructing grid polygons\")\n",
    "    ]\n",
    "    gdf_points['geometry'] = polygons\n",
    "    grid_gdf = gdf_points[[lat_col, lon_col, 'polygon_id', 'geometry']].copy()\n",
    "\n",
    "    # 4) Reproject grid to the target crs\n",
    "    grid_gdf = grid_gdf.to_crs(crs)\n",
    "\n",
    "    # 5) Ensure municipalities are in the target crs\n",
    "    if municipalities_gdf.crs != crs:\n",
    "        municipalities_gdf = municipalities_gdf.to_crs(crs)\n",
    "\n",
    "    # 6) Overlay to get coverage fraction\n",
    "    overlay_gdf = gpd.overlay(municipalities_gdf, grid_gdf, how='intersection')\n",
    "    overlay_gdf['cell_area'] = overlay_gdf.geometry.area\n",
    "    poly_area_sum = overlay_gdf.groupby('polygon_id')['cell_area'].sum().rename('polygon_total_area')\n",
    "    overlay_gdf = overlay_gdf.merge(poly_area_sum, on='polygon_id', how='left')\n",
    "    overlay_gdf['coverage_fraction'] = overlay_gdf['cell_area'] / overlay_gdf['polygon_total_area']\n",
    "    coverage_table = overlay_gdf[['polygon_id', municipality_id_col, 'coverage_fraction']].copy()\n",
    "\n",
    "    # 7) Merge main df with polygon_id\n",
    "    df_merged = df.merge(grid_gdf[[lat_col, lon_col, 'polygon_id']], on=[lat_col, lon_col], how='left')\n",
    "\n",
    "    # 8) If time_col exists, create a 'year' for chunking\n",
    "    if time_col in df_merged.columns:\n",
    "        df_merged['year'] = df_merged[time_col].dt.year\n",
    "\n",
    "    # 9) Identify numeric columns\n",
    "    exclude_cols = {lat_col, lon_col, time_col, 'polygon_id', 'year', 'geometry'}\n",
    "    numeric_cols = df_merged.select_dtypes(include=[np.number]).columns.difference(exclude_cols)\n",
    "\n",
    "    # 10) Group and aggregate\n",
    "    final_results = []\n",
    "    if 'year' in df_merged.columns:\n",
    "        years = sorted(df_merged['year'].dropna().unique())\n",
    "        for y in years:\n",
    "            chunk_df = df_merged[df_merged['year'] == y].copy()\n",
    "            if chunk_df.empty:\n",
    "                continue\n",
    "            merged_cov = chunk_df.merge(coverage_table, on='polygon_id', how='left')\n",
    "            merged_cov.dropna(subset=['coverage_fraction'], inplace=True)\n",
    "            for col in numeric_cols:\n",
    "                merged_cov[f'{col}_wtd'] = merged_cov[col] * merged_cov['coverage_fraction']\n",
    "            grouped = merged_cov.groupby([municipality_id_col, time_col])[\n",
    "                [f'{col}_wtd' for col in numeric_cols]\n",
    "            ].sum().reset_index()\n",
    "            final_results.append(grouped)\n",
    "        aggregated = pd.concat(final_results, ignore_index=True) if final_results else pd.DataFrame()\n",
    "    else:\n",
    "        merged_cov = df_merged.merge(coverage_table, on='polygon_id', how='left')\n",
    "        merged_cov.dropna(subset=['coverage_fraction'], inplace=True)\n",
    "        for col in numeric_cols:\n",
    "            merged_cov[f'{col}_wtd'] = merged_cov[col] * merged_cov['coverage_fraction']\n",
    "        aggregated = merged_cov.groupby(municipality_id_col)[\n",
    "            [f'{col}_wtd' for col in numeric_cols]\n",
    "        ].sum().reset_index()\n",
    "\n",
    "    return aggregated\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
